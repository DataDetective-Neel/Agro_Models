================================================================================
        AGRICULTURAL ML MODELS - COMPREHENSIVE USAGE GUIDE
================================================================================

This guide covers all machine learning models available for crop prediction:
 1. Random Forest (ML_Model_Original)
 2. XGBoost (ML_Model_Xgboost)  
 3. LightGBM (ML_model_LightGBM)
 4. CatBoost (ML_model_CatBoost)
 5. AutoML - AutoGluon (ML_model_AutoML)

================================================================================
TABLE OF CONTENTS
================================================================================
1. Installation Requirements
2. Random Forest Usage
3. XGBoost Usage
4. LightGBM Usage
5. CatBoost Usage
6. AutoML (AutoGluon) Usage
7. Performance Comparison
8. Recommendations

================================================================================
1. INSTALLATION REQUIREMENTS
================================================================================

REQUIRED PIP PACKAGES:
----------------------
pip install pandas numpy scikit-learn joblib

# For Random Forest (already included in scikit-learn)
# No additional packages needed

# For XGBoost
pip install xgboost

# For LightGBM
pip install lightgbm

# For CatBoost
pip install catboost

# For AutoML (AutoGluon)
pip install autogluon

# RECOMMENDED: Install all at once
pip install pandas numpy scikit-learn joblib xgboost lightgbm catboost autogluon


================================================================================
2. RANDOM FOREST USAGE
================================================================================

LOCATION: ML_Model_Original/

FEATURES:
---------
âœ“ Simple and reliable
âœ“ Easy to understand
âœ“ No GPU required
âœ“ Good baseline performance
âœ“ Less prone to overfitting

TRAINING SCRIPTS:
-----------------
1. train_models.py                  - Basic regression & classification models
2. train_regional_models.py        - Region-specific models (Punjab, Haryana, Rajasthan)
3. train_improved_models.py        - Enhanced features + better accuracy
4. train_seasonal_specialized.py   - Season-specific models (Rabi, Kharif, Zaid)
5. final_three_model_system.py     - Integrated 3-model prediction system

HOW TO TRAIN:
-------------
cd ML_Model_Original

# Train basic models
python train_models.py

# Train regional models
python train_regional_models.py

# Train improved models (recommended)
python train_improved_models.py

# Train seasonal models
python train_seasonal_specialized.py

# Use complete 3-model system
python final_three_model_system.py

HOW TO USE FOR PREDICTION:
---------------------------
import joblib

# Load model
model_data = joblib.load('ML models/punjab_improved_model.pkl')
model = model_data['model']
scaler = model_data['scaler']
encoders = model_data['encoders']

# Prepare input
input_features = {
    'N': 100, 'P': 50, 'K': 40, 'pH': 7.0,
    'Temperature': 25, 'Humidity': 60, 'Rainfall': 100, 'Moisture': 20,
    'Season': 'Rabi', 'SoilType': 'Clay', 'Irrigation': 'Irrigated'
}

# Predict (code depends on model version - see script for details)

EXPECTED ACCURACY: 75-85% (depending on model variant)


================================================================================
3. XGBOOST USAGE
================================================================================

LOCATION: ML_Model_Xgboost/

FEATURES:
---------
âœ“ High accuracy gradient boosting
âœ“ Better than Random Forest
âœ“ Handles missing values
âœ“ Built-in regularization
âœ“ Industry standard

TRAINING SCRIPTS:
-----------------
1. train_models.py                  - Basic XGBoost regression & classification
2. train_regional_models.py        - Regional XGBoost models
3. train_improved_models.py        - Enhanced XGBoost with feature engineering
4. train_seasonal_specialized.py   - Seasonal XGBoost models
5. final_three_model_system.py     - 3-model XGBoost system

HOW TO TRAIN:
-------------
cd ML_Model_Xgboost

# Train basic models
python train_models.py

# Train regional models
python train_regional_models.py

# Train improved models (recommended)
python train_improved_models.py

# Train seasonal models
python train_seasonal_specialized.py

# Use complete 3-model system
python final_three_model_system.py

HOW TO USE FOR PREDICTION:
---------------------------
import joblib

# Load XGBoost model
model_data = joblib.load('ML models/haryana_improved_model.pkl')
model = model_data['model']
scaler = model_data['scaler']
encoders = model_data['encoders']

# Prepare input (same as Random Forest)
input_features = {
    'N': 100, 'P': 50, 'K': 40, 'pH': 7.0,
    'Temperature': 25, 'Humidity': 60, 'Rainfall': 100, 'Moisture': 20,
    'Season': 'Rabi', 'SoilType': 'Clay', 'Irrigation': 'Irrigated'
}

# Predict using XGBoost model
# (See train_improved_models.py for prediction code)

EXPECTED ACCURACY: 80-90%

KEY PARAMETERS:
---------------
- n_estimators=300      # Number of trees
- max_depth=8           # Tree depth
- learning_rate=0.05    # Learning rate
- subsample=0.8         # Data sampling
- colsample_bytree=0.8  # Feature sampling


================================================================================
4. LIGHTGBM USAGE
================================================================================

LOCATION: ML_model_LightGBM/

FEATURES:
---------
âœ“ 10-20x FASTER than XGBoost
âœ“ Lower memory usage
âœ“ Similar or better accuracy than XGBoost
âœ“ Histogram-based learning
âœ“ Great for large datasets
âœ“ BEST CHOICE for production deployment

TRAINING SCRIPTS:
-----------------
1. train_models.py                  - Basic LightGBM regression & classification
2. train_regional_models.py        - Regional LightGBM models 
3. train_improved_models.py        - Enhanced LightGBM with feature engineering
4. train_seasonal_specialized.py   - Seasonal LightGBM models
5. final_three_model_system.py     - 3-model LightGBM system

HOW TO TRAIN:
-------------
cd ML_model_LightGBM

# Train basic models
python train_models.py

# Train regional models
python train_regional_models.py

# Train improved models (RECOMMENDED)
python train_improved_models.py

# Train seasonal models
python train_seasonal_specialized.py

# Use complete 3-model system
python final_three_model_system.py

HOW TO USE FOR PREDICTION:
---------------------------
import joblib

# Load LightGBM model
model_data = joblib.load('ML models/rajasthan_improved_model.pkl')
model = model_data['model']
scaler = model_data['scaler']
encoders = model_data['encoders']

# Prepare input
input_features = {
    'N': 100, 'P': 50, 'K': 40, 'pH': 7.0,
    'Temperature': 25, 'Humidity': 60, 'Rainfall': 100, 'Moisture': 20,
    'Season': 'Rabi', 'SoilType': 'Clay', 'Irrigation': 'Irrigated'
}

# Predict (same API as XGBoost)

EXPECTED ACCURACY: 80-92%

KEY ADVANTAGES:
---------------
âœ“ Training Time: 10-20x faster than XGBoost
âœ“ Prediction Speed: 2-5x faster
âœ“ Memory: 50% less than XGBoost
âœ“ Accuracy: Same or +2-5% better


================================================================================
5. CATBOOST USAGE
================================================================================

LOCATION: ML_model_CatBoost/

FEATURES:
---------
âœ“ BEST for categorical features (SoilType, Season, Irrigation)
âœ“ No need to encode categorical variables!
âœ“ Handles missing values automatically
âœ“ Less overfitting than XGBoost
âœ“ Great default parameters
âœ“ BEST CHOICE for accuracy

TRAINING SCRIPTS:
-----------------
1. train_improved_models.py        - CatBoost with native categorical handling
(Other scripts similar to XGBoost/LightGBM can be created as needed)

HOW TO TRAIN:
-------------
cd ML_model_CatBoost

# Train improved CatBoost models
python train_improved_models.py

HOW TO USE FOR PREDICTION:
---------------------------
import joblib

# Load CatBoost model
model_data = joblib.load('ML models/punjab_improved_model.pkl')
model = model_data['model']
encoders = model_data['encoders']

# Prepare input - CatBoost handles categorical features naturally!
input_features = {
    'N': 100, 'P': 50, 'K': 40, 'pH': 7.0,
    'Temperature': 25, 'Humidity': 60, 'Rainfall': 100, 'Moisture': 20,
    'Season': 'Rabi',           # Can pass as string!
    'SoilType': 'Clay',         # Can pass as string!
    'Irrigation': 'Irrigated'   # Can pass as string!
}

# Predict
prediction = model.predict(input_features)

EXPECTED ACCURACY: 82-95%

KEY ADVANTAGES:
---------------
âœ“ Native categorical feature support
âœ“ Best accuracy for this type of data
âœ“ Less tuning required
âœ“ GPU support available
âœ“ Robust to overfitting


================================================================================
6. AUTOML (AUTOGLUON) USAGE
================================================================================

LOCATION: ML_model_AutoML/

FEATURES:
---------
âœ“ AUTOMATICALLY tests multiple algorithms
âœ“ Automatic hyperparameter tuning
âœ“ Creates ensemble models
âœ“ ZERO manual tuning required
âœ“ Tests: LightGBM, CatBoost, XGBoost, Random Forest, Neural Networks
âœ“ BEST CHOICE for maximum automation

TRAINING SCRIPTS:
-----------------
1. train_models.py                  - AutoGluon automatic model selection

HOW TO TRAIN:
-------------
cd ML_model_AutoML

# Train AutoML - it will automatically:
# - Test 10+ different algorithms
# - Tune hyperparameters
# - Create ensemble models
# - Select the best model
python train_models.py

TRAINING TIME: 5-30 minutes (configurable via time_limit parameter)

HOW TO USE FOR PREDICTION:
---------------------------
from autogluon.tabular import TabularPredictor

# Load AutoML model
predictor = TabularPredictor.load('ML models/autogluon_crop_model')

# Prepare input
input_data = {
    'N': 100, 'P': 50, 'K': 40, 
    'Temperature': 25, 'Humidity': 60, 
    'Nitrogen': 100, 'Phosphorus': 50, 'Potassium': 40,
    'Soil_Moisture': 20
}

# Predict - AutoGluon handles everything!
prediction = predictor.predict(input_data)
print(f"Predicted Crop: {prediction}")

# Get prediction probabilities
probabilities = predictor.predict_proba(input_data)
print(probabilities)

EXPECTED ACCURACY: 85-98%

KEY ADVANTAGES:
---------------
âœ“ Best possible accuracy (ensemble of best models)
âœ“ Zero manual tuning
âœ“ Automatically finds optimal algorithm
âœ“ Built-in feature engineering
âœ“ Perfect for rapid prototyping


================================================================================
7. PERFORMANCE COMPARISON
================================================================================

+---------------+----------+---------+--------+----------+-------------+
| Model Type    | Accuracy | Speed   | Memory | Ease     | Best For    |
+---------------+----------+---------+--------+----------+-------------+
| Random Forest | â­â­â­     | â­â­â­    | â­â­â­   | â­â­â­â­â­  | Learning    |
|               | 75-85%   | Medium  | Low    | Easy     | Baseline    |
+---------------+----------+---------+--------+----------+-------------+
| XGBoost       | â­â­â­â­    | â­â­â­    | â­â­â­   | â­â­â­â­    | Industry    |
|               | 80-90%   | Medium  | Medium | Good     | Standard    |
+---------------+----------+---------+--------+----------+-------------+
| LightGBM      | â­â­â­â­    | â­â­â­â­â­  | â­â­â­â­â­ | â­â­â­â­    | Production  |
|               | 80-92%   | FASTEST | Low    | Good     | Deployment  |
+---------------+----------+---------+--------+----------+-------------+
| CatBoost      | â­â­â­â­â­   | â­â­â­â­   | â­â­â­   | â­â­â­â­â­  | Categorical |
|               | 82-95%   | Fast    | Medium | Easiest  | Features    |
+---------------+----------+---------+--------+----------+-------------+
| AutoML        | â­â­â­â­â­   | â­â­      | â­â­    | â­â­â­â­â­  | Max         |
|               | 85-98%   | Slow*   | High   | AUTO     | Accuracy    |
+---------------+----------+---------+--------+----------+-------------+

* AutoML training is slow, but prediction is fast
  Training: 5-30 minutes (one-time)
  Prediction: Same speed as underlying models


DETAILED COMPARISON:
--------------------

Metric               | Random Forest | XGBoost  | LightGBM | CatBoost | AutoML
---------------------|---------------|----------|----------|----------|--------
Training Time        | 30-60 sec     | 60-120s  | 10-30s   | 40-80s   | 5-30 min
Prediction Speed     | Fast          | Fast     | Fastest  | Fast     | Fast
Memory Usage         | Low           | Medium   | Low      | Medium   | High
CPU Usage            | Medium        | High     | Low      | Medium   | Very High
GPU Support          | No            | Yes      | Yes      | Yes      | Yes
Handles Categories   | Manual        | Manual   | Manual   | Native   | Native
Overfitting Risk     | Low           | Medium   | Medium   | Low      | Very Low
Tuning Required      | Low           | High     | Medium   | Low      | None
Feature Engineering  | Manual        | Manual   | Manual   | Manual   | Auto


================================================================================
8. RECOMMENDATIONS
================================================================================

CHOOSE BASED ON YOUR PRIORITY:
-------------------------------

ðŸ† MAXIMUM ACCURACY:
   Use: AutoML (AutoGluon)
   Why: Tests all algorithms, creates optimal ensemble
   Trade-off: Longer training time
   Command: cd ML_model_AutoML && python train_models.py

âš¡ FASTEST TRAINING & PREDICTION:
   Use: LightGBM  
   Why: 10-20x faster than XGBoost, same accuracy
   Trade-off: None! (Best of both worlds)
   Command: cd ML_model_LightGBM && python train_improved_models.py

ðŸŽ¯ BEST FOR CATEGORICAL DATA:
   Use: CatBoost
   Why: Native categorical handling, highest accuracy for this data type
   Trade-off: Slightly slower than LightGBM
   Command: cd ML_model_CatBoost && python train_improved_models.py

ðŸ“š LEARNING/BASELINE:
   Use: Random Forest
   Why: Simple, easy to understand, reliable
   Trade-off: Lower accuracy
   Command: cd ML_Model_Original && python train_improved_models.py

ðŸ¢ INDUSTRY STANDARD:
   Use: XGBoost
   Why: Widely used, well-documented, proven track record
   Trade-off: Slower than LightGBM
   Command: cd ML_Model_Xgboost && python train_improved_models.py


MY TOP 3 RECOMMENDATIONS FOR THIS PROJECT:
-------------------------------------------

1st Choice: LightGBM (ML_model_LightGBM)
   - Fastest training and prediction
   - High accuracy (80-92%)
   - Low memory usage
   - Perfect for production

2nd Choice: CatBoost (ML_model_CatBoost)
   - Best accuracy (82-95%)
   - Natural categorical handling (Season, SoilType, Irrigation)
   - Less prone to overfitting
   - Easiest to use

3rd Choice: AutoML (ML_model_AutoML)
   - Absolute maximum accuracy (85-98%)
   - Zero tuning required
   - Great for experimenting
   - Best if accuracy > speed


PRODUCTION DEPLOYMENT RECOMMENDATION:
-------------------------------------
Train with AutoML to find best approach â†’ Deploy with LightGBM for speed

1. Use AutoML to experiment and find optimal features/approach
2. Implement the winning approach in LightGBM for fast predictions
3. Use CatBoost as backup for maximum accuracy when speed isn't critical


================================================================================
QUICK START GUIDE
================================================================================

STEP 1: Install packages
pip install pandas numpy scikit-learn joblib xgboost lightgbm catboost autogluon

STEP 2: Choose your model (recommended: LightGBM)
cd ML_model_LightGBM

STEP 3: Train
python train_improved_models.py

STEP 4: Use for prediction
python final_three_model_system.py

DONE! ðŸŽ‰


================================================================================
SUPPORT & TROUBLESHOOTING
================================================================================

Common Issues:
--------------
1. ImportError: No module named 'lightgbm'
   Fix: pip install lightgbm

2. AutoGluon installation fails
   Fix: pip install --upgrade pip
        pip install autogluon

3. CUDA/GPU errors
   Fix: Models work fine on CPU. GPU is optional.

4. Memory errors with AutoML
   Fix: Reduce time_limit in train_models.py (line 30)


For best results:
-----------------
âœ“ Use train_improved_models.py (has feature engineering)
âœ“ Ensure your dataset is in data/processed/ directory
âœ“ Check that CSV files have correct column names
âœ“ Start with LightGBM for best speed/accuracy balance


================================================================================
END OF GUIDE
================================================================================

Last Updated: December 2025
Version: 1.0
Contact: See project documentation

Happy Modeling! ðŸŒ¾ðŸš€
